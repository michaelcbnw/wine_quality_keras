{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3ad4e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68e823a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.05</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.05</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.05</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.06</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.06</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.0              0.27         0.36            20.7       0.05   \n",
       "1            6.3              0.30         0.34             1.6       0.05   \n",
       "2            8.1              0.28         0.40             6.9       0.05   \n",
       "3            7.2              0.23         0.32             8.5       0.06   \n",
       "4            7.2              0.23         0.32             8.5       0.06   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 45.0                 170.0     1.00  3.00       0.45   \n",
       "1                 14.0                 132.0     0.99  3.30       0.49   \n",
       "2                 30.0                  97.0     1.00  3.26       0.44   \n",
       "3                 47.0                 186.0     1.00  3.19       0.40   \n",
       "4                 47.0                 186.0     1.00  3.19       0.40   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      8.8        6  \n",
       "1      9.5        6  \n",
       "2     10.1        6  \n",
       "3      9.9        6  \n",
       "4      9.9        6  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('D:\\Kuliah\\Skripsi\\Wine Quality Mix.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "185e0f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "quality = df['quality'].values\n",
    "category = []\n",
    "for i in quality:\n",
    "    if i < 4:\n",
    "        category.append(\"Bad\")\n",
    "    elif i > 6:\n",
    "        category.append(\"Very Good\")\n",
    "    else:\n",
    "        category.append(\"Good\")\n",
    "        \n",
    "# Membuat data baru\n",
    "category = pd.DataFrame(data=category, columns=['category'])\n",
    "data = pd.concat([df, category], axis=1)\n",
    "data.drop(columns='quality', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fd1ab0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3233</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.29</td>\n",
       "      <td>11.8</td>\n",
       "      <td>0.04</td>\n",
       "      <td>21.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>3.18</td>\n",
       "      <td>0.34</td>\n",
       "      <td>11.9</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2550</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.14</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.05</td>\n",
       "      <td>27.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>3.21</td>\n",
       "      <td>0.48</td>\n",
       "      <td>9.4</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1541</th>\n",
       "      <td>7.1</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.03</td>\n",
       "      <td>29.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.32</td>\n",
       "      <td>9.1</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4320</th>\n",
       "      <td>6.4</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.35</td>\n",
       "      <td>7.7</td>\n",
       "      <td>0.06</td>\n",
       "      <td>45.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.50</td>\n",
       "      <td>9.5</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6047</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.47</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.23</td>\n",
       "      <td>0.52</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4301</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.23</td>\n",
       "      <td>8.9</td>\n",
       "      <td>0.11</td>\n",
       "      <td>22.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.01</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.5</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5073</th>\n",
       "      <td>6.9</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.09</td>\n",
       "      <td>19.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.35</td>\n",
       "      <td>0.78</td>\n",
       "      <td>9.5</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3676</th>\n",
       "      <td>5.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.03</td>\n",
       "      <td>25.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>3.31</td>\n",
       "      <td>0.40</td>\n",
       "      <td>13.6</td>\n",
       "      <td>Very Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4814</th>\n",
       "      <td>5.7</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.35</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>17.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>3.18</td>\n",
       "      <td>0.67</td>\n",
       "      <td>12.4</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>6.4</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>9.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>2.97</td>\n",
       "      <td>0.29</td>\n",
       "      <td>10.8</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "3233            6.2              0.20         0.29            11.8       0.04   \n",
       "2550            6.2              0.33         0.14             4.8       0.05   \n",
       "1541            7.1              0.53         0.24             0.8       0.03   \n",
       "4320            6.4              0.26         0.35             7.7       0.06   \n",
       "6047           10.0              0.35         0.47             2.0       0.06   \n",
       "4301            7.2              0.34         0.23             8.9       0.11   \n",
       "5073            6.9              0.50         0.04             1.5       0.09   \n",
       "3676            5.3              0.30         0.30             1.2       0.03   \n",
       "4814            5.7              0.40         0.35             5.1       0.03   \n",
       "594             6.4              0.48         0.06             1.0       0.03   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "3233                 21.0                  93.0     0.99  3.18       0.34   \n",
       "2550                 27.0                 128.0     0.99  3.21       0.48   \n",
       "1541                 29.0                  86.0     0.99  3.16       0.32   \n",
       "4320                 45.0                 191.0     1.00  3.16       0.50   \n",
       "6047                  6.0                  11.0     1.00  3.23       0.52   \n",
       "4301                 22.0                 155.0     1.00  3.01       0.58   \n",
       "5073                 19.0                  49.0     1.00  3.35       0.78   \n",
       "3676                 25.0                  93.0     0.99  3.31       0.40   \n",
       "4814                 17.0                 113.0     0.99  3.18       0.67   \n",
       "594                   9.0                 131.0     0.99  2.97       0.29   \n",
       "\n",
       "      alcohol   category  \n",
       "3233     11.9       Good  \n",
       "2550      9.4       Good  \n",
       "1541      9.1       Good  \n",
       "4320      9.5       Good  \n",
       "6047     12.0       Good  \n",
       "4301      9.5       Good  \n",
       "5073      9.5       Good  \n",
       "3676     13.6  Very Good  \n",
       "4814     12.4       Good  \n",
       "594      10.8       Good  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e29c2904",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['category'], axis=1)\n",
    "y = data['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e5194b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_enc(lbl):\n",
    "    mi = min(lbl)\n",
    "    length = len(bin(max(lbl)-mi+1)[2:])\n",
    "    enc = []\n",
    "    for i in lbl:\n",
    "        b = bin(i-mi)[2:].zfill(length)\n",
    "        enc.append([int(n) for n in b])\n",
    "    return enc\n",
    "\n",
    "def onehot_enc(lbl, min_val=0):\n",
    "    mi = min(lbl)\n",
    "    enc = np.full((len(lbl), max(lbl)-mi+1), min_val, np.int8)\n",
    "    \n",
    "    for i, x in enumerate(lbl):\n",
    "        enc[i, x-mi] = 1\n",
    "    return enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8243092c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_dec(enc, mi=0):\n",
    "    lbl = []\n",
    "    for e in enc:\n",
    "        rounded = [int(round(x)) for x in e]\n",
    "        string = ''.join(str(x) for x in rounded)\n",
    "        num = int(string,2) + mi\n",
    "        lbl.append(num)\n",
    "    return lbl\n",
    "\n",
    "def onehot_dec(enc, mi=0):\n",
    "    return [np.argmax(e)+mi for e in enc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97100164",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sig(X):\n",
    "    return [1/(1+np.exp(-1)) for x in X]\n",
    "\n",
    "def sigd(X):\n",
    "    output = []\n",
    "    for i, x in enumerate(X):\n",
    "        s = sig([X])[0]\n",
    "        output.append(s*(1-s))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfcdd7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bp_fit(X, target, layer_conf, max_epoch, max_error=.1, learn_rate=.1, \n",
    "           print_per_epoch=100):\n",
    "    nin = [np.empty(i) for i in layer_conf]\n",
    "    n = [np.empty(j+1) if i<len(layer_conf)-1\n",
    "        else np.empty(j) for i,j in enumerate(layer_conf)]\n",
    "    w = np.array([np.random.rand(layer_conf[i]+1, layer_conf[i+1]) \n",
    "                  for i in range(len(layer_conf)-1)])\n",
    "    dw = [np.empty((layer_conf[i]+1, layer_conf[i+1]))\n",
    "         for i in range(len(layer_conf)-1)]\n",
    "    d = [np.empty(s) for s in layer_conf[1:]]\n",
    "    din = [np.empty(s) for s in layer_conf[1: -1]]\n",
    "    epoch = 0\n",
    "    mse = 1\n",
    "    \n",
    "    for i in range(0, len(n)-1):\n",
    "        n[i][-1]=1\n",
    "    \n",
    "    while(max_epoch == -1 or epoch<max_epoch) and mse>max_error:\n",
    "        epoch +=1\n",
    "        mse = 0\n",
    "        \n",
    "        for r in range(len(X)):\n",
    "            n[0][:-1] = X[r]\n",
    "            \n",
    "            for L in range(1, len(layer_conf)):\n",
    "                nin[L] = np.dot(n[L-1], w[L-1])\n",
    "                n[L][:len(nin[L])] = sig(nin[L])\n",
    "                \n",
    "            e = target[r]- n[-1]\n",
    "            mse += sum(e **2)\n",
    "            d[-1]= e * sigd(nin[-1])\n",
    "            dw[-1]= learn_rate * d[-1] * n[-2].reshape((-1,1))\n",
    "            \n",
    "            for L in range(len(layer_conf)-1, 1, -1):\n",
    "                din[L-2]=np.dot(d[L-1], np.transpose(w[L-1][:-1]))\n",
    "                d[L-2]=din[L-2]*np.array(sigd(nin[L-1]))\n",
    "                dw[L-2]=(learn_rate*d[L-2])*n[L-2].reshape((-1,1))\n",
    "            w +=dw\n",
    "        mse /= len(X)\n",
    "    \n",
    "    if print_per_epoch > -1 and epoch % print_per_epoch == 0:\n",
    "        print(f'epoch {epoch}, MSE: {mse}')\n",
    "    return w, epoch, mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ec4cd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bp_predict(X,w):\n",
    "    n = [np.empty(len(i)) for i in w]\n",
    "    nin = [np.empty(len(i[0])) for i in w]\n",
    "    predict = []\n",
    "    \n",
    "    n.append(np.empty(len(w[-1][0])))\n",
    "    \n",
    "    for x in X:\n",
    "        n[0][:-1] = x\n",
    "        \n",
    "        for L in range(0, len(w)):\n",
    "            nin[L] = np.dot(n[L], w[L])\n",
    "        predict.append(n[-1].copy())\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8dcf5313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 2 1 1 1 2 1 1 1 2 2 2 1 1 0 1 0 1 2 2 2 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 1 1 1 1 1 2 2 2 2 1 1 2 0 1 1 2 1 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encode = LabelEncoder()\n",
    "y = label_encode.fit_transform(y)\n",
    "#y = y.reshape(len(y),1)\n",
    "print(y[232:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82e0cf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y = data[['category']].replace(['Bad', 'Good', 'Very Good'],[0,1,2])\n",
    "#y.sample(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "678ff77e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_norm = minmax_scale(X)\n",
    "y_enc = onehot_enc(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76b97540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "print(y_enc[232:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bdd0dcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_norm,y_enc,test_size=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "115f26a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-60633fcbeffb>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  w = np.array([np.random.rand(layer_conf[i]+1, layer_conf[i+1])\n",
      "<ipython-input-9-60633fcbeffb>:38: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  w +=dw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1000, MSE: 1.1412227789056537\n",
      "Epochs: 1000, MSE: 1.1412227789056537\n"
     ]
    }
   ],
   "source": [
    "w, ep, mse = bp_fit(X_train, y_train, layer_conf=(11,5,3),learn_rate=.1, max_epoch=1000, max_error=.1, print_per_epoch=25)\n",
    "\n",
    "print(f'Epochs: {ep}, MSE: {mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b842a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "True: [1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 2, 1, 2, 1, 1, 1, 2, 1, 0, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 2, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2, 1, 1, 2, 1, 2, 1, 1, 1, 2, 2, 1, 1, 0, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 2, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 2, 2, 1, 1, 1, 1, 1, 2, 2, 1, 2, 1, 1, 2, 2, 1, 1, 1, 2, 2, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 2, 2, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 2, 1, 1, 1, 1, 2, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 2, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 2, 2, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 2, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 2, 2, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 1, 2, 1, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2, 2, 2, 1, 1, 2, 2, 1, 1, 1, 2, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 2, 2, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 2, 1, 2, 2, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 2, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 0, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 2, 2, 1, 2, 2, 2, 1, 2, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 2, 1, 1, 0, 1, 2, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 0, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1]\n",
      "Accuracy: 79.8974358974359 %\n"
     ]
    }
   ],
   "source": [
    "predict = bp_predict(X_test, w)\n",
    "predict = onehot_dec(predict)\n",
    "y_test = onehot_dec(y_test)\n",
    "acc = accuracy_score(predict, y_test)\n",
    "print(f'Output: {predict}')\n",
    "print(f'True: {y_test}')\n",
    "print(f'Accuracy: {acc*100} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee5cefc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_confmat(actual, predicted):\n",
    "\n",
    "    # extract the different classes\n",
    "    classes = np.unique(actual)\n",
    "\n",
    "    # initialize the confusion matrix\n",
    "    confmat = np.zeros((len(classes), len(classes)))\n",
    "\n",
    "    # loop across the different combinations of actual / predicted classes\n",
    "    for i in range(len(classes)):\n",
    "        for j in range(len(classes)):\n",
    "\n",
    "           # count the number of instances in each combination of actual / predicted classes\n",
    "           confmat[i, j] = np.sum((actual == classes[i]) & (predicted == classes[j]))\n",
    "\n",
    "    return confmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cfc77785",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0.    7.    0.]\n",
      " [   0. 1558.    0.]\n",
      " [   0.  385.    0.]]\n"
     ]
    }
   ],
   "source": [
    "#print(comp_confmat(y_test, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fc326120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(y_test, predict)\n",
    "cm_df = pd.DataFrame(cm, index=[0, 1, 2], columns=[0,1,2])\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm_df, annot=True)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predict')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b5dfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def printMetrics(actual, predictions):\n",
    "#    assert len(actual) == len(prediction)\n",
    "#    correct = 0\n",
    "#    for i in range(len(actial)):\n",
    "#        correct += 1\n",
    "#    return(correct/float(len(actual))*100.00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d5b6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#class kFoldCv:\n",
    "#    def crossValSplit(self, dataset, nfolds):\n",
    "#        dataSplit = list()\n",
    "#        dataCopy = list(dataset)\n",
    "#        foldSize = int(len(dataset)/nfolds)\n",
    "#        for _ in range(nfolds):\n",
    "#            fold = list()\n",
    "#            while len(fold) < foldSize:\n",
    "#                index = randrange(len(dataCopy))\n",
    "#                fold.append(dataCopy.pop(index))\n",
    "#            dataSplit.append(fold)\n",
    "#        return dataSplit\n",
    "    \n",
    "#    def kFCEval(self, dataset, nfolds):\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
