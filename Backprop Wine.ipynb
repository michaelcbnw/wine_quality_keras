{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3ad4e63",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32me:\\Learning System\\Python\\wine_quality_keras\\Backprop Wine.ipynb Cell 1'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/Learning%20System/Python/wine_quality_keras/Backprop%20Wine.ipynb#ch0000000?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Learning%20System/Python/wine_quality_keras/Backprop%20Wine.ipynb#ch0000000?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Learning%20System/Python/wine_quality_keras/Backprop%20Wine.ipynb#ch0000000?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m \u001b[39mimport\u001b[39;00m minmax_scale\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68e823a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.05</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.05</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.05</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.06</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.06</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.0              0.27         0.36            20.7       0.05   \n",
       "1            6.3              0.30         0.34             1.6       0.05   \n",
       "2            8.1              0.28         0.40             6.9       0.05   \n",
       "3            7.2              0.23         0.32             8.5       0.06   \n",
       "4            7.2              0.23         0.32             8.5       0.06   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 45.0                 170.0     1.00  3.00       0.45   \n",
       "1                 14.0                 132.0     0.99  3.30       0.49   \n",
       "2                 30.0                  97.0     1.00  3.26       0.44   \n",
       "3                 47.0                 186.0     1.00  3.19       0.40   \n",
       "4                 47.0                 186.0     1.00  3.19       0.40   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      8.8        6  \n",
       "1      9.5        6  \n",
       "2     10.1        6  \n",
       "3      9.9        6  \n",
       "4      9.9        6  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Wine Quality Mix.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "185e0f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "quality = df['quality'].values\n",
    "category = []\n",
    "for i in quality:\n",
    "    if i < 4:\n",
    "        category.append(\"Bad\")\n",
    "    elif i > 6:\n",
    "        category.append(\"Very Good\")\n",
    "    else:\n",
    "        category.append(\"Good\")\n",
    "        \n",
    "# Membuat data baru\n",
    "category = pd.DataFrame(data=category, columns=['category'])\n",
    "data = pd.concat([df, category], axis=1)\n",
    "data.drop(columns='quality', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fd1ab0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3233</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.29</td>\n",
       "      <td>11.8</td>\n",
       "      <td>0.04</td>\n",
       "      <td>21.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>3.18</td>\n",
       "      <td>0.34</td>\n",
       "      <td>11.9</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2550</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.14</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.05</td>\n",
       "      <td>27.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>3.21</td>\n",
       "      <td>0.48</td>\n",
       "      <td>9.4</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1541</th>\n",
       "      <td>7.1</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.03</td>\n",
       "      <td>29.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.32</td>\n",
       "      <td>9.1</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4320</th>\n",
       "      <td>6.4</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.35</td>\n",
       "      <td>7.7</td>\n",
       "      <td>0.06</td>\n",
       "      <td>45.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.50</td>\n",
       "      <td>9.5</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6047</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.47</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.23</td>\n",
       "      <td>0.52</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4301</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.23</td>\n",
       "      <td>8.9</td>\n",
       "      <td>0.11</td>\n",
       "      <td>22.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.01</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.5</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5073</th>\n",
       "      <td>6.9</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.09</td>\n",
       "      <td>19.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.35</td>\n",
       "      <td>0.78</td>\n",
       "      <td>9.5</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3676</th>\n",
       "      <td>5.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.03</td>\n",
       "      <td>25.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>3.31</td>\n",
       "      <td>0.40</td>\n",
       "      <td>13.6</td>\n",
       "      <td>Very Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4814</th>\n",
       "      <td>5.7</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.35</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>17.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>3.18</td>\n",
       "      <td>0.67</td>\n",
       "      <td>12.4</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>6.4</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>9.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>2.97</td>\n",
       "      <td>0.29</td>\n",
       "      <td>10.8</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "3233            6.2              0.20         0.29            11.8       0.04   \n",
       "2550            6.2              0.33         0.14             4.8       0.05   \n",
       "1541            7.1              0.53         0.24             0.8       0.03   \n",
       "4320            6.4              0.26         0.35             7.7       0.06   \n",
       "6047           10.0              0.35         0.47             2.0       0.06   \n",
       "4301            7.2              0.34         0.23             8.9       0.11   \n",
       "5073            6.9              0.50         0.04             1.5       0.09   \n",
       "3676            5.3              0.30         0.30             1.2       0.03   \n",
       "4814            5.7              0.40         0.35             5.1       0.03   \n",
       "594             6.4              0.48         0.06             1.0       0.03   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "3233                 21.0                  93.0     0.99  3.18       0.34   \n",
       "2550                 27.0                 128.0     0.99  3.21       0.48   \n",
       "1541                 29.0                  86.0     0.99  3.16       0.32   \n",
       "4320                 45.0                 191.0     1.00  3.16       0.50   \n",
       "6047                  6.0                  11.0     1.00  3.23       0.52   \n",
       "4301                 22.0                 155.0     1.00  3.01       0.58   \n",
       "5073                 19.0                  49.0     1.00  3.35       0.78   \n",
       "3676                 25.0                  93.0     0.99  3.31       0.40   \n",
       "4814                 17.0                 113.0     0.99  3.18       0.67   \n",
       "594                   9.0                 131.0     0.99  2.97       0.29   \n",
       "\n",
       "      alcohol   category  \n",
       "3233     11.9       Good  \n",
       "2550      9.4       Good  \n",
       "1541      9.1       Good  \n",
       "4320      9.5       Good  \n",
       "6047     12.0       Good  \n",
       "4301      9.5       Good  \n",
       "5073      9.5       Good  \n",
       "3676     13.6  Very Good  \n",
       "4814     12.4       Good  \n",
       "594      10.8       Good  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e29c2904",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['category'], axis=1)\n",
    "y = data['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e5194b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_enc(lbl):\n",
    "    mi = min(lbl)\n",
    "    length = len(bin(max(lbl)-mi+1)[2:])\n",
    "    enc = []\n",
    "    for i in lbl:\n",
    "        b = bin(i-mi)[2:].zfill(length)\n",
    "        enc.append([int(n) for n in b])\n",
    "    return enc\n",
    "\n",
    "def onehot_enc(lbl, min_val=0):\n",
    "    mi = min(lbl)\n",
    "    enc = np.full((len(lbl), max(lbl)-mi+1), min_val, np.int8)\n",
    "    \n",
    "    for i, x in enumerate(lbl):\n",
    "        enc[i, x-mi] = 1\n",
    "    return enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8243092c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_dec(enc, mi=0):\n",
    "    lbl = []\n",
    "    for e in enc:\n",
    "        rounded = [int(round(x)) for x in e]\n",
    "        string = ''.join(str(x) for x in rounded)\n",
    "        num = int(string,2) + mi\n",
    "        lbl.append(num)\n",
    "    return lbl\n",
    "\n",
    "def onehot_dec(enc, mi=0):\n",
    "    return [np.argmax(e)+mi for e in enc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97100164",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sig(X):\n",
    "    return [1/(1+np.exp(-1)) for x in X]\n",
    "\n",
    "def sigd(X):\n",
    "    output = []\n",
    "    for i, x in enumerate(X):\n",
    "        s = sig([X])[0]\n",
    "        output.append(s*(1-s))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfcdd7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bp_fit(X, target, layer_conf, max_epoch, max_error=.1, learn_rate=.1, \n",
    "           print_per_epoch=100):\n",
    "    nin = [np.empty(i) for i in layer_conf]\n",
    "    n = [np.empty(j+1) if i<len(layer_conf)-1\n",
    "        else np.empty(j) for i,j in enumerate(layer_conf)]\n",
    "    w = np.array([np.random.rand(layer_conf[i]+1, layer_conf[i+1]) \n",
    "                  for i in range(len(layer_conf)-1)])\n",
    "    dw = [np.empty((layer_conf[i]+1, layer_conf[i+1]))\n",
    "         for i in range(len(layer_conf)-1)]\n",
    "    d = [np.empty(s) for s in layer_conf[1:]]\n",
    "    din = [np.empty(s) for s in layer_conf[1: -1]]\n",
    "    epoch = 0\n",
    "    mse = 1\n",
    "    \n",
    "    for i in range(0, len(n)-1):\n",
    "        n[i][-1]=1\n",
    "    \n",
    "    while(max_epoch == -1 or epoch<max_epoch) and mse>max_error:\n",
    "        epoch +=1\n",
    "        mse = 0\n",
    "        \n",
    "        for r in range(len(X)):\n",
    "            n[0][:-1] = X[r]\n",
    "            \n",
    "            for L in range(1, len(layer_conf)):\n",
    "                nin[L] = np.dot(n[L-1], w[L-1])\n",
    "                n[L][:len(nin[L])] = sig(nin[L])\n",
    "                \n",
    "            e = target[r]- n[-1]\n",
    "            mse += sum(e **2)\n",
    "            d[-1]= e * sigd(nin[-1])\n",
    "            dw[-1]= learn_rate * d[-1] * n[-2].reshape((-1,1))\n",
    "            \n",
    "            for L in range(len(layer_conf)-1, 1, -1):\n",
    "                din[L-2]=np.dot(d[L-1], np.transpose(w[L-1][:-1]))\n",
    "                d[L-2]=din[L-2]*np.array(sigd(nin[L-1]))\n",
    "                dw[L-2]=(learn_rate*d[L-2])*n[L-2].reshape((-1,1))\n",
    "            w +=dw\n",
    "        mse /= len(X)\n",
    "    \n",
    "    if print_per_epoch > -1 and epoch % print_per_epoch == 0:\n",
    "        print(f'epoch {epoch}, MSE: {mse}')\n",
    "    return w, epoch, mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ec4cd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bp_predict(X,w):\n",
    "    n = [np.empty(len(i)) for i in w]\n",
    "    nin = [np.empty(len(i[0])) for i in w]\n",
    "    predict = []\n",
    "    \n",
    "    n.append(np.empty(len(w[-1][0])))\n",
    "    \n",
    "    for x in X:\n",
    "        n[0][:-1] = x\n",
    "        \n",
    "        for L in range(0, len(w)):\n",
    "            nin[L] = np.dot(n[L], w[L])\n",
    "        predict.append(n[-1].copy())\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8dcf5313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 2 1 1 1 2 1 1 1 2 2 2 1 1 0 1 0 1 2 2 2 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 1 1 1 1 1 2 2 2 2 1 1 2 0 1 1 2 1 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encode = LabelEncoder()\n",
    "y = label_encode.fit_transform(y)\n",
    "#y = y.reshape(len(y),1)\n",
    "print(y[232:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82e0cf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y = data[['category']].replace(['Bad', 'Good', 'Very Good'],[0,1,2])\n",
    "#y.sample(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "678ff77e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_norm = minmax_scale(X)\n",
    "y_enc = onehot_enc(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76b97540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "print(y_enc[232:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bdd0dcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_norm,y_enc,test_size=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "115f26a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-60633fcbeffb>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  w = np.array([np.random.rand(layer_conf[i]+1, layer_conf[i+1])\n",
      "<ipython-input-9-60633fcbeffb>:38: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  w +=dw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1000, MSE: 1.1412227789056537\n",
      "Epochs: 1000, MSE: 1.1412227789056537\n"
     ]
    }
   ],
   "source": [
    "w, ep, mse = bp_fit(X_train, y_train, layer_conf=(11,5,3),learn_rate=.1, max_epoch=1000, max_error=.1, print_per_epoch=25)\n",
    "\n",
    "print(f'Epochs: {ep}, MSE: {mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b842a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "True: [1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 2, 1, 2, 1, 1, 1, 2, 1, 0, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 2, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2, 1, 1, 2, 1, 2, 1, 1, 1, 2, 2, 1, 1, 0, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 2, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 2, 2, 1, 1, 1, 1, 1, 2, 2, 1, 2, 1, 1, 2, 2, 1, 1, 1, 2, 2, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 2, 2, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 2, 1, 1, 1, 1, 2, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 2, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 2, 2, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 2, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 2, 2, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 1, 2, 1, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2, 2, 2, 1, 1, 2, 2, 1, 1, 1, 2, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 2, 2, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 2, 1, 2, 2, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 2, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 0, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 2, 2, 1, 2, 2, 2, 1, 2, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 2, 1, 1, 0, 1, 2, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 0, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1]\n",
      "Accuracy: 79.8974358974359 %\n"
     ]
    }
   ],
   "source": [
    "predict = bp_predict(X_test, w)\n",
    "predict = onehot_dec(predict)\n",
    "y_test = onehot_dec(y_test)\n",
    "acc = accuracy_score(predict, y_test)\n",
    "print(f'Output: {predict}')\n",
    "print(f'True: {y_test}')\n",
    "print(f'Accuracy: {acc*100} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee5cefc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_confmat(actual, predicted):\n",
    "\n",
    "    # extract the different classes\n",
    "    classes = np.unique(actual)\n",
    "\n",
    "    # initialize the confusion matrix\n",
    "    confmat = np.zeros((len(classes), len(classes)))\n",
    "\n",
    "    # loop across the different combinations of actual / predicted classes\n",
    "    for i in range(len(classes)):\n",
    "        for j in range(len(classes)):\n",
    "\n",
    "           # count the number of instances in each combination of actual / predicted classes\n",
    "           confmat[i, j] = np.sum((actual == classes[i]) & (predicted == classes[j]))\n",
    "\n",
    "    return confmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc77785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0.    7.    0.]\n",
      " [   0. 1558.    0.]\n",
      " [   0.  385.    0.]]\n"
     ]
    }
   ],
   "source": [
    "print(comp_confmat(y_test, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b5dfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printMetrics(actual, predictions):\n",
    "    assert len(actual) == len(predictions)\n",
    "    correct = 0\n",
    "    for i in range(len(actual)):\n",
    "        correct += 1\n",
    "    return(correct/float(len(actual))*100.00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbb2f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class kFoldCv:\n",
    "    def crossValSplit(self, dataset, nfolds):\n",
    "        dataSplit = list()\n",
    "        dataCopy = list(dataset)\n",
    "        foldSize = int(len(dataset)/nfolds)\n",
    "        for _ in range(nfolds):\n",
    "            fold = list()\n",
    "            while len(fold) < foldSize:\n",
    "                index = range(len(dataCopy))\n",
    "                fold.append(dataCopy.pop(index))\n",
    "            dataSplit.append(fold)\n",
    "        return dataSplit\n",
    "    \n",
    "    def kFCEval(self, dataset, nfolds):\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9a5d2e0360dac8c0de02b5e3d4d318b7c331dfd489174cdd131d99b3d609e651"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
